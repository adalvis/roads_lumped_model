{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Surface Sediment Storage\n",
    "Amanda Manaster  \n",
    "*2019.10.21*  \n",
    "\n",
    "---\n",
    "When a truck passes, two processes occur: **crushing and pumping**.  \n",
    "    &emsp;*Crushing* creates more fine sediment in the existing sediment matrix by breaking down larger particles.  \n",
    "    &emsp;*Pumping* makes fine sediment available for transport (i.e., adds the fine sediment to the transport available fines storage layer). \n",
    "\n",
    "We can think of the total storage as:  \n",
    "$S=S_f+S_s+S_b$  \n",
    "    &emsp;$S_f$= transport available fines (TAF) storage term [$m$]  \n",
    "    &emsp;$S_s$= surfacing storage term; combination of fines ($S_{s_f}$), coarse particles ($S_{s_c}$) [$m$]  \n",
    "    &emsp;$S_b$= ballast storage term; combination of fines, 20-30% ($S_{b_f}$), large rocks, 70-80% ($S_{b_r}$) [$m$]  \n",
    "\n",
    "And the net mass balance as:  \n",
    "$∆S=-\\frac{V_{s,out}}{A}=-H_{s,out}$\n",
    "\n",
    "$∆S$ = total change in storage [$m$]  \n",
    "$V_{s,out}$ = lithified equivalent volume of sediment leaving the road prism [$m^3$]  \n",
    "$A$ = representative area of road [$m^2$]  \n",
    "$H_{s,out}$ = lithified equivalent depth of sediment leaving the road prism [$m$]    \n",
    "\n",
    "---\n",
    "## A Tri-Layered Conceptualization:\n",
    "![](TruckPass_TriLayer_Labels.png)\n",
    "\n",
    "---  \n",
    "First, load in packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate empty lists for model run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3.66 #representative segment of road, m\n",
    "\n",
    "depth = []\n",
    "rainfall = []\n",
    "t = []\n",
    "len_s = []\n",
    "truck_pass = []\n",
    "\n",
    "model_end = 52560 #hours == 6 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a model loop to generate random rainfall based on averages from Peter Eagleson's _Ecohydrology_ and to generate stochastic truck passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) #Use seed to ensure consistent results with each run\n",
    "time = 0\n",
    "T_b = 0\n",
    "T_r = 0\n",
    "\n",
    "while time < model_end:\n",
    "    truck = 0\n",
    "    time_loop = T_b+T_r\n",
    "    \n",
    "    T_b = np.random.exponential(90.5) #average inter-storm duration\n",
    "    T_r = np.random.exponential(5.41) #average storm duration\n",
    "    r = np.random.exponential(2)      #average intensity\n",
    "    \n",
    "    if time_loop/24 >= 1:\n",
    "        day = int(time_loop/24)\n",
    "        frac_day = time_loop/24 - int(time_loop/24)\n",
    "        \n",
    "        for num in range(day):\n",
    "            truck += np.random.randint(0,10)\n",
    "            \n",
    "        truck += round(np.random.randint(0,10)*frac_day)\n",
    "    else:\n",
    "        frac_day = time_loop/24 - int(time_loop/24)\n",
    "        truck = round(np.random.randint(0,10)*frac_day)\n",
    "    \n",
    "    len_s.append(T_r)\n",
    "    depth.append(r*T_r)\n",
    "    rainfall.append(r)\n",
    "    t.append(time)\n",
    "    truck_pass.append(truck)\n",
    "    \n",
    "    time += T_b + T_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have a hefty data set, we wrap these data in a Pandas dataframe for ease of plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() #Create dataframe\n",
    "\n",
    "df['time'] = t\n",
    "df['day'] = np.divide(t,24).astype('int64')\n",
    "df['storm_depth'] = depth\n",
    "df['rainfall_rate'] = rainfall\n",
    "df['storm_length'] = len_s\n",
    "df['truck_pass'] = truck_pass\n",
    "\n",
    "day0 = datetime(2018, 10, 1)\n",
    "df.set_index(pd.DatetimeIndex([day0+timedelta(hours=time) for time in df.time]), inplace=True) #Set index of dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We resample the data to get a daily time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.resample('D').sum().fillna(0)\n",
    "df2.truck_pass = df2.truck_pass.round()\n",
    "df2['day'] = np.arange(0, len(df2), 1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can plot the stochastically generated daily rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticklabels = [item.strftime('%b %Y') for item in df2.index[::366]]\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "df2.plot(y='storm_depth', ax=ax, legend=False, kind='bar', width=5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Rainfall (mm)')\n",
    "plt.title('Daily rainfall', fontweight='bold', fontsize=14)\n",
    "plt.xticks(np.arange(0,366*len(ticklabels),366), ticklabels, rotation=0)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\Rainfall.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the time step of the model, our rainfall, and our truck passes, we can start to calculate sediment transport rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants\n",
    "rho_w = 1000 #kg/m^3\n",
    "rho_s = 2650 #kg/m^3\n",
    "g = 9.81 #m/s^2\n",
    "S = 0.08\n",
    "tau_c = 0.094 #N/m^2; assuming d50 is approx. 0.058 mm; value from https://pubs.usgs.gov/sir/2008/5093/table7.html\n",
    "d50 = 5.8e-5 #m\n",
    "n = 0.03 #approx Manning's n value for overland flow\n",
    "\n",
    "#Calculate water depth\n",
    "H = ((n*df.rainfall_rate*2.77778e-7*L)/(S**(1/2)))**(3/5)\n",
    "\n",
    "#Calculate shear stress\n",
    "df['shear_stress'] = rho_w*g*(H)*S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate sediment transport rate\n",
    "df['q_s'] = ((10**(-4.348))/(rho_s*d50**(0.811)))*(df.shear_stress-tau_c)**(2.457)\n",
    "df.fillna(0, inplace=True) #Get rid of NaNs\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resample to daily data again\n",
    "df3 = df.resample('D').mean().fillna(0)\n",
    "df3['day'] = np.arange(0, len(df3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sediment transport rates over time\n",
    "fig2, ax2 = plt.subplots(figsize=(7,5))\n",
    "df3.plot(y='q_s', ax=ax2, color = 'peru', legend=False)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(r'Sediment transport rate $(m^2/s)$')\n",
    "plt.title('Sediment transport rates', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\Sediment.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can look at the evolution of the road through time!\n",
    "\n",
    "## Create loop that goes through model time:\n",
    "1. Create fines storage, $S_{f_0}$; surfacing storage, $S_{s_0}$; and ballast storage, $S_{b_0}$:  \n",
    "    &emsp;$S_{f_{0}} = 0$  \n",
    "    \n",
    "    &emsp;$S_{s_0}=S_{{sc}_0}+S_{{sf}_0}$     \n",
    "    &emsp;&emsp;$S_{s_{f_0}}=h_{s_0}*f_{sf_0}*(1-p_s)$   \n",
    "    &emsp;&emsp;$S_{s_{c_0}}=h_{s_0}*f_{sc_0}*(1-p_s)$  \n",
    "    \n",
    "    &emsp;$S_{b_0}=S_{{bf}_0}+S_{{br}_0}$  \n",
    "    &emsp;&emsp;$S_{{bf}_0}=h_{b_0}*f_{bf_0}*(1-p_b)$   \n",
    "    &emsp;&emsp;$S_{{br}_0}=h_{b_0}*f_{br_0}*(1-p_b)$  \n",
    "\n",
    "\n",
    "2. Loop through dataframe:\n",
    "    * Calculate $S_{f_i}$  \n",
    "        * Check if available sediment is greater than transport capacity:\n",
    "            * If *yes*, **condition 1** applies:  \n",
    "              $H_{s,out_i}=\\frac{q_{s_i}*t_{s_i}}{L}$    \n",
    "              $∆S_{f_i}=u_p*n_i-H_{s,out_i}$     \n",
    "              \n",
    "            * If *no*, **condition 2** applies:    \n",
    "              $H_{s,out_i}=min(u_p*n_i+S_{f_i},\\frac{q_{s_i}*t_{s_i}}{L})$  \n",
    "              $∆S_{f_i}=u_p*n_i-H_{s,out_i}$  \n",
    "              \n",
    "        * Update the fines storage term:  \n",
    "           $S_{f_{i}} = S_{f_{i-1}} + \\Delta S_{f_{i}}$  \n",
    "               \n",
    "    * Calculate $S_{s_i}$  \n",
    "       $S_{s_i} = S_{sc_i} + S_{sf_i}$  \n",
    "       $S_{sc_i}=e^{-kn_i}\\left(S_{sc_{i-1}}+\\frac{u_c}{k}\\right)-\\frac{u_c}{k}$  \n",
    "       $S_{sf_i}={{(1-e}^{-kn_i})(S}_{sc_{i-1}}+\\frac{u_c}{k})-n_i\\left(u_c+u_p-u_f\\right)+S_{sf_{i-1}}$  \n",
    "    * Calculate $S_{b_i}$  \n",
    "       $S_{b_i}= n_i(u_c - u_f)+ S_{b_{i-1}}$\n",
    "       \n",
    "    \n",
    "For simplicity, we'll assume the following:  \n",
    "    &emsp;$h_{s_0}$ = 0.23 [m] (https://www.fhwa.dot.gov/construction/pubs/ots15002.pdf, A4 Table 3)   \n",
    "    &emsp;$f_{sf_0}$ = 0.275 [-] (from Palix watershed analysis)  \n",
    "    &emsp;$f_{sc_0}$ = 0.725 [-] (from Palix watershed analysis)  \n",
    "    &emsp;$p_s$ = 0.275 [-] (Applied Hydrogeology 3rd Ed. by C.W. Fetter, Table 3.4)   \n",
    "    &emsp;$h_{b_0}$ = 0.60 [m]  \n",
    "    &emsp;$f_{bf_0}$ = 0.20 [-]  \n",
    "    &emsp;$f_{br_0}$ = 0.80 [-]  \n",
    "    &emsp;$p_b$ = 0.20 [-]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants\n",
    "h_s = 0.23\n",
    "f_sf = 0.275\n",
    "f_sc = 0.725\n",
    "p_s = 0.275\n",
    "\n",
    "h_b = 0.60\n",
    "f_bf = 0.20\n",
    "f_br = 0.80\n",
    "p_b = 0.20\n",
    "\n",
    "#The following four constants can be adjusted based on observations\n",
    "kas = 1e-7 #crushing constant... value is easily changeable\n",
    "kab = 1e-8\n",
    "u_p = 1.37e-8 #m (5e-7m^3/3.66 m^2)\n",
    "u_f = 1e-7 #m\n",
    "u_c = 1.0e-8 #m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe for our storage calculations\n",
    "df_storage = pd.DataFrame()\n",
    "\n",
    "df_storage['time'] = t\n",
    "df_storage['day'] = np.divide(t,24).astype('int64')\n",
    "day0 = datetime(2018, 10, 1)\n",
    "df_storage.set_index(pd.DatetimeIndex([day0+timedelta(hours=time) for time in df_storage.time]), inplace=True)\n",
    "\n",
    "df_storage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a condition column based on sediment transport capacity vs sediment supply\n",
    "sed_avail = u_p*df.truck_pass\n",
    "sed_cap = (df.storm_length*3600*df.q_s)/L\n",
    "value = (sed_avail-sed_cap)\n",
    "\n",
    "df_storage['value'] = value\n",
    "df_storage['condition'] = np.where(df_storage.value > 0, 'Conditon 1', 'Condition 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Step 1!\n",
    "#Initialize numpy arrays for calculations\n",
    "dS_f = np.zeros(len(df))\n",
    "S_f = np.zeros(len(df))\n",
    "S_s = np.zeros(len(df))\n",
    "S_sc = np.zeros(len(df))\n",
    "S_sf = np.zeros(len(df))\n",
    "S_b = np.zeros(len(df))\n",
    "S_bc = np.zeros(len(df))\n",
    "S_bf = np.zeros(len(df))\n",
    "Hs_out = np.zeros(len(df))\n",
    "n_tp = df.truck_pass.to_numpy()\n",
    "\n",
    "\n",
    "#Initial conditions for fines, surfacing, ballast\n",
    "S_f[0] = 0\n",
    "S_s[0] = h_s*(f_sf + f_sc)*(1-p_s)\n",
    "S_sc[0] = h_s*(f_sc)*(1-p_s)\n",
    "S_sf[0] = h_s*(f_sf)*(1-p_s)\n",
    "S_b[0] = h_b*(f_bf + f_br)*(1-p_b)\n",
    "S_bc[0] = h_b*(f_br)*(1-p_b)\n",
    "S_bf[0] = h_b*(f_bf)*(1-p_b)\n",
    "\n",
    "#Step 2!\n",
    "for i in range(1, len(df)):\n",
    "    S_bc[i] = S_bc[i-1] - kab*S_bc[i-1]/S_b[i-1]*n_tp[i]\n",
    "    S_sc[i] = S_sc[i-1] - kas*S_sc[i-1]/S_s[i-1]*n_tp[i]\n",
    "    \n",
    "    S_bf[i] = S_bf[i-1] + kab*S_bc[i-1]/S_b[i-1]*n_tp[i] - u_f*S_bf[i-1]/S_b[i-1]*n_tp[i]\n",
    "    S_sf[i] = S_sf[i-1] + kas*S_sc[i-1]/S_s[i-1]*n_tp[i] - u_p*S_sf[i-1]/S_s[i-1]*n_tp[i] + u_f*S_bf[i-1]/S_b[i-1]*n_tp[i]\n",
    "        \n",
    "    S_s[i] = S_sc[i] + S_sf[i]\n",
    "    S_b[i] = S_bc[i] + S_bf[i]\n",
    "        \n",
    "    sed_avail[i] = u_p*S_sf[i]/S_s[i]*n_tp[i]    \n",
    "        \n",
    "    if value[i] < 0:\n",
    "        Hs_out[i] = np.minimum(sed_avail[i]+S_f[i-1], sed_cap[i])\n",
    "        dS_f[i] = sed_avail[i] - Hs_out[i]\n",
    "\n",
    "    else:\n",
    "        Hs_out[i] = sed_cap[i]\n",
    "        dS_f[i] = sed_avail[i] - Hs_out[i]\n",
    "\n",
    "    S_f[i] = S_f[i-1] + dS_f[i] if (S_f[i-1] + dS_f[i]) > 0 else 0\n",
    "\n",
    "#Add all numpy arrays to the Pandas dataframe\n",
    "df_storage['dS_f'] = dS_f\n",
    "df_storage['S_f'] = S_f\n",
    "df_storage['S_s'] = S_s\n",
    "df_storage['S_sc'] = S_sc\n",
    "df_storage['S_sf'] = S_sf\n",
    "df_storage['S_b'] = S_b\n",
    "df_storage['Hs_out'] = Hs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at our dataframe\n",
    "df_storage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_storage.resample('D').mean().fillna(method='ffill')\n",
    "df4['day'] = np.arange(0, len(df4), 1)\n",
    "df4['S_f_mm'] = df4.S_f*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots(figsize=(7,5))\n",
    "df4.plot(y='S_f_mm', ax=ax3, color = 'mediumseagreen', legend=False)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(r'Fine sediment storage $(mm)$')\n",
    "plt.title('Fine sediment storage', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df_storage.resample('H').mean().fillna(method='ffill')\n",
    "df5['hour'] = np.arange(0, len(df5), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, ax5 = plt.subplots(3, figsize=(8,10), sharex = 'col', gridspec_kw={'hspace': 0.05})\n",
    "\n",
    "df5.plot(y='S_s', ax=ax5[0], color = 'mediumpurple', legend=False)\n",
    "ax5[0].set(ylabel=r'Total surfacing $(m)$')\n",
    "ax5[0].set_title('Surfacing storage', fontweight='bold', fontsize=14)\n",
    "\n",
    "df5.plot(y='S_sc', ax=ax5[1], color = 'cornflowerblue', legend=False)\n",
    "ax5[1].set(ylabel=r'Coarse surfacing $(m)$')\n",
    "\n",
    "df5.plot(y='S_sf', ax=ax5[2], color = 'salmon', legend=False)\n",
    "ax5[2].set(ylabel=r'Fine surfacing $(m)$')\n",
    "plt.xlabel('Date')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7, ax7 = plt.subplots(figsize=(7,5))\n",
    "df5.plot(y='S_b', ax=ax7, color = 'teal', legend=False)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(r'Ballast storage $(m)$')\n",
    "plt.title('Ballast storage', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data by water year\n",
    "yr_1 = df_storage.Hs_out['2018-10-01':'2019-09-30'].sum()\n",
    "yr_2 = df_storage.Hs_out['2019-10-01':'2020-09-30'].sum()\n",
    "yr_3 = df_storage.Hs_out['2020-10-01':'2021-09-30'].sum()\n",
    "yr_4 = df_storage.Hs_out['2021-10-01':'2022-09-30'].sum()\n",
    "yr_5 = df_storage.Hs_out['2022-10-01':'2023-09-30'].sum()\n",
    "yr_6 = df_storage.Hs_out['2023-10-01':'2024-09-30'].sum()\n",
    "\n",
    "#Multiply Hs_out\n",
    "sed_area = np.multiply([yr_1, yr_2, yr_3, yr_4, yr_5, yr_6], L)\n",
    "sed_load = np.multiply(sed_area, rho_s)\n",
    "years = [2019, 2020, 2021, 2022, 2023, 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig8, ax8 = plt.subplots(figsize=(7,5))\n",
    "plt.bar(years, sed_load/(S**2), color = 'mediumvioletred')\n",
    "plt.xlabel('Water year')\n",
    "plt.ylabel(r'Sediment load/$LS^2$ $(kg/m)$')\n",
    "plt.title('Yearly sediment load per meter of road', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do a sanity check. (i.e., is mass conserved?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_sum_m2 = df_storage.Hs_out.sum()\n",
    "sed_sum_kg_m = sed_sum_m2*rho_s*L\n",
    "round(sed_sum_kg_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (df_storage.S_s[0]-df_storage.S_s[len(df_storage)-1])\n",
    "b = (df_storage.S_b[0]-df_storage.S_b[len(df_storage)-1])\n",
    "f = (df_storage.S_f[0]-df_storage.S_f[len(df_storage)-1])\n",
    "\n",
    "round((s+b+f)*rho_s*L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
