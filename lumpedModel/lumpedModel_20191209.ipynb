{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Surface Sediment Storage\n",
    "Amanda Manaster  \n",
    "*2019.12.09*  \n",
    "\n",
    "---\n",
    "When a truck passes, two processes occur: **crushing and pumping**.  \n",
    "    &emsp;*Crushing* creates more fine sediment in the existing sediment matrix by breaking down larger particles.  \n",
    "    &emsp;*Pumping* makes fine sediment available for transport (i.e., adds the fine sediment to the transport available fines storage layer). \n",
    "\n",
    "We can think of the total storage as:  \n",
    "$S=S_f+S_s+S_b$  \n",
    "    &emsp;$S_f$= transport available fines (TAF) storage term [$m$]  \n",
    "    &emsp;$S_s$= surfacing storage term; combination of fines ($S_{s_f}$), coarse particles ($S_{s_c}$) [$m$]  \n",
    "    &emsp;$S_b$= ballast storage term; combination of fines, 20-30% ($S_{b_f}$), large rocks, 70-80% ($S_{b_r}$) [$m$]  \n",
    "\n",
    "And the net mass balance as:  \n",
    "$∆S=-\\frac{V_{s,out}}{A}=-H_{s,out}$\n",
    "\n",
    "$∆S$ = total change in storage [$m$]  \n",
    "$V_{s,out}$ = volume of sediment leaving the road prism [$m^3$]  \n",
    "$A$ = representative area of road [$m^2$]  \n",
    "$H_{s,out}$ = depth of sediment leaving the road prism [$m$]    \n",
    "\n",
    "---\n",
    "## A Tri-Layered Conceptualization:\n",
    "![](RoadTriLayer.png)  \n",
    "\n",
    "---  \n",
    "First, load in packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style(ticks=False, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate empty lists for model run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_depth = []\n",
    "rainfall_rate = []\n",
    "delta_t = []\n",
    "storm_length = []\n",
    "truck_pass = []\n",
    "total_t = []\n",
    "\n",
    "model_end = 175200 #20 yrs = 175200 hrs; 100 yrs = 876000 hrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a model loop to generate random rainfall based on averages from Peter Eagleson's _Ecohydrology_ and to generate stochastic truck passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) #Use seed to ensure consistent results with each run\n",
    "time = 0 #model time; initial\n",
    "T_b = 0  #average inter-storm duration; initial\n",
    "T_r = 0  #average storm duration; initial\n",
    "r = 0    #average intensity; initial\n",
    "\n",
    "while time < model_end:\n",
    "    truck = 0\n",
    "    time_step = T_b+T_r\n",
    "    \n",
    "    if time_step/24 >= 1:\n",
    "        day = int(time_step/24)\n",
    "        frac_day = time_step/24 - int(time_step/24)\n",
    "        \n",
    "        for num in range(day):\n",
    "            truck += np.random.randint(0,10)\n",
    "            \n",
    "        truck += round(np.random.randint(0,10)*frac_day)\n",
    "    else:\n",
    "        frac_day = time_step/24 - int(time_step/24)\n",
    "        truck = round(np.random.randint(0,10)*frac_day)\n",
    "    \n",
    "    storm_length.append(T_r)             #length of storm\n",
    "    storm_depth.append(r*T_r)            #depth of storm\n",
    "    rainfall_rate.append(r)              #rate of rainfall\n",
    "    delta_t.append(time_step)            #length of each time step; variable\n",
    "    total_t.append(time)                 #model time\n",
    "    truck_pass.append(truck)             #number of truck passes\n",
    "    \n",
    "    T_b = np.random.exponential(90.5)    #average inter-storm duration, hr\n",
    "    T_r = np.random.exponential(2.705*2) #average storm duration, hr\n",
    "    r = np.random.exponential(2)         #average intensity, mm/hr\n",
    "    \n",
    "    time += T_b+T_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have a hefty data set, we wrap these data in a Pandas dataframe for ease of plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() #Create dataframe\n",
    "\n",
    "df['time'] = total_t\n",
    "df['delta_t'] = delta_t\n",
    "df['day'] = np.divide(total_t,24).astype('int64')\n",
    "df['storm_depth'] = storm_depth\n",
    "df['rainfall_rate'] = rainfall_rate\n",
    "df['storm_length'] = storm_length\n",
    "df['truck_pass'] = truck_pass\n",
    "\n",
    "day0 = datetime(2018, 10, 1)\n",
    "df.set_index(pd.DatetimeIndex([day0+timedelta(hours=time) for time in df.time]), inplace=True) #Set index of dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We resample the data to get a daily time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = df.resample('D').sum().fillna(0)\n",
    "df_day.truck_pass = df_day.truck_pass.round()\n",
    "df_day['day'] = np.arange(0, len(df_day), 1)\n",
    "df_day.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can plot the stochastically generated daily rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ticklabels = [item.strftime('%Y') for item in df_day.index[::366*2]]\n",
    "#fig, ax = plt.subplots(figsize=(10,4))\n",
    "#df_day.plot(y='storm_depth', ax=ax, legend=False, kind='bar', width=7)\n",
    "#plt.xlabel('Date')\n",
    "#plt.ylabel('Rainfall (mm)')\n",
    "#plt.title('Daily rainfall', fontweight='bold', fontsize=14)\n",
    "#plt.xticks(np.arange(0,366*2*len(ticklabels)+366,366*2), ticklabels, rotation=0)\n",
    "#plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\Rainfall.png', dpi=300)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticklabels = [item.strftime('%Y') for item in df_day.index[::366*2]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "df_day.plot(y='truck_pass', ax=ax, color = '#8a0c80', legend=False, label='Truck passes', \n",
    "            kind='bar', width=7)\n",
    "ax.set_xlabel('Date', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Truck passes', fontsize=14, fontweight='bold')\n",
    "ax.grid(False)\n",
    "\n",
    "ax1 = ax.twinx()\n",
    "df_day.plot(y='storm_depth', ax=ax1, color='#0c3c8a', legend=False, label='Storm depth', kind='bar', width=7)\n",
    "ax1.set_ylabel(r'Storm depth $(mm)$', fontsize=14, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "ax1.grid(False)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax.transAxes)\n",
    "ax.set_xticks(np.arange(0,366*2*len(ticklabels),366*2))\n",
    "ax.set_xticklabels(ticklabels, rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\Rainfall_Truck.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the time step of the model, our rainfall, and our truck passes, we can start to calculate sediment transport rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants\n",
    "L = 4.57 #representative segment of road, m\n",
    "rho_w = 1000 #kg/m^3\n",
    "rho_s = 2650 #kg/m^3\n",
    "g = 9.81 #m/s^2\n",
    "S = 0.0825 #m/m; 8% long slope, 2% lat slope\n",
    "tau_c = 0.0939 #N/m^2; assuming d50 is approx. 0.0580 mm; value from https://pubs.usgs.gov/sir/2008/5093/table7.html\n",
    "d50 = 5.8e-5 #m\n",
    "d95 = 0.07 #m\n",
    "n_s = 0.03 #approx Manning's n for grains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can look at the evolution of the road through time!\n",
    "\n",
    "## Create loop that goes through model time:\n",
    "1. Create fines storage, $S_{f_0}$; surfacing storage, $S_{s_0}$; and ballast storage, $S_{b_0}$:  \n",
    "    &emsp;$S_{f_{0}} = 0$  \n",
    "    \n",
    "    &emsp;$S_{s_0}=S_{{sc}_0}+S_{{sf}_0}$     \n",
    "    &emsp;&emsp;$S_{s_{f_0}}=h_{s_0}*f_{sf_0}$   \n",
    "    &emsp;&emsp;$S_{s_{c_0}}=h_{s_0}*f_{sc_0}$  \n",
    "    \n",
    "    &emsp;$S_{b_0}=S_{{bf}_0}+S_{{bc}_0}$  \n",
    "    &emsp;&emsp;$S_{{bf}_0}=h_{b_0}*f_{bf_0}$   \n",
    "    &emsp;&emsp;$S_{{bc}_0}=h_{b_0}*f_{bc_0}$  \n",
    "\n",
    "\n",
    "2. Loop through dataframe:\n",
    "    * Calculate $S_{f_i}$                 \n",
    "    * Calculate $S_{s_i}$  \n",
    "    * Calculate $S_{b_i}$       \n",
    "    \n",
    "For simplicity, we'll assume the following:  \n",
    "    &emsp;$h_{s_0}$ = 0.23 [m] (https://www.fhwa.dot.gov/construction/pubs/ots15002.pdf, A4 Table 3)   \n",
    "    &emsp;$f_{sf_0}$ = 0.275 [-] (from Palix watershed analysis)  \n",
    "    &emsp;$f_{sc_0}$ = 0.725 [-] (from Palix watershed analysis)  \n",
    "    &emsp;$h_{b_0}$ = 0.60 [m]  \n",
    "    &emsp;$f_{bf_0}$ = 0.20 [-]  \n",
    "    &emsp;$f_{bc_0}$ = 0.80 [-]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants\n",
    "h_s = 0.23\n",
    "f_sf = 0.275\n",
    "f_sc = 0.725\n",
    "\n",
    "h_b = 5\n",
    "f_bf = 0.20\n",
    "f_br = 0.80\n",
    "\n",
    "#The following four constants can be adjusted based on observations\n",
    "kas = 1.37e-8 #crushing constant... value is easily changeable\n",
    "kab = 1.0e-8\n",
    "u_p = 4.69e-6 #m (2.14e-5m^3/4.57 m^2)  6 tires * 0.225 m width * 0.005 m length * 3.175e-3 m treads\n",
    "u_f = 2.345e-6 #m\n",
    "p = 0.20 #[-] (Applied Hydrogeology 3rd Ed. by C.W. Fetter, Table 3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe for our storage calculations\n",
    "df_storage = pd.DataFrame()\n",
    "\n",
    "df_storage['time'] = total_t\n",
    "df_storage['day'] = np.divide(total_t,24).astype('int64')\n",
    "day0 = datetime(2018, 10, 1)\n",
    "df_storage.set_index(pd.DatetimeIndex([day0+timedelta(hours=time) for time in df_storage.time]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Step 1!\n",
    "#Initialize numpy arrays for calculations\n",
    "dS_f = np.zeros(len(df))\n",
    "S_f = np.zeros(len(df))\n",
    "S_s = np.zeros(len(df))\n",
    "S_sc = np.zeros(len(df))\n",
    "S_sf = np.zeros(len(df))\n",
    "S_b = np.zeros(len(df))\n",
    "S_bc = np.zeros(len(df))\n",
    "S_bf = np.zeros(len(df))\n",
    "Hs_out = np.zeros(len(df))\n",
    "q_s = np.zeros(len(df))\n",
    "h_f = np.zeros(len(df))\n",
    "k_s = np.zeros(len(df))\n",
    "H = np.zeros(len(df))\n",
    "tau = np.zeros(len(df))\n",
    "shear_stress = np.zeros(len(df))\n",
    "n = np.zeros(len(df))\n",
    "f_s = np.zeros(len(df))\n",
    "\n",
    "n_tp = df.truck_pass.to_numpy()\n",
    "t = df.delta_t.to_numpy()\n",
    "t_storm = df.storm_length.to_numpy()\n",
    "rainfall = df.rainfall_rate.to_numpy()\n",
    "\n",
    "q_f1 = np.zeros(len(df))\n",
    "q_f2 = np.zeros(len(df))\n",
    "q_as = np.zeros(len(df))\n",
    "q_ab = np.zeros(len(df))\n",
    "sed_avail = np.zeros(len(df))\n",
    "sed_cap = np.zeros(len(df))\n",
    "value = np.zeros(len(df))\n",
    "\n",
    "#Initial conditions for fines, surfacing, ballast\n",
    "n[0] = 0.0475*(d95)**(1/6)\n",
    "f_s[0] = (n_s/n[0])**(1.5)\n",
    "S_f[0] = 0\n",
    "S_s[0] = h_s*(f_sf + f_sc)\n",
    "S_sc[0] = h_s*(f_sc)\n",
    "S_sf[0] = h_s*(f_sf)\n",
    "S_b[0] = h_b*(f_bf + f_br)\n",
    "S_bc[0] = h_b*(f_br)\n",
    "S_bf[0] = h_b*(f_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2!\n",
    "for i in range(1, len(df)):\n",
    "    q_f1[i] = u_p*(S_sf[i-1]/S_s[i-1])*n_tp[i]/(t[i]*3600)\n",
    "    q_f2[i] = u_f*(S_bf[i-1]/S_b[i-1])*n_tp[i]/(t[i]*3600)\n",
    "    q_as[i] = kas*(S_sc[i-1]/S_s[i-1])*n_tp[i]/(t[i]*3600)\n",
    "    q_ab[i] = kab*(S_bc[i-1]/S_b[i-1])*n_tp[i]/(t[i]*3600)\n",
    "    \n",
    "    S_bc[i] = S_bc[i-1] - q_ab[i]*(t[i]*3600)\n",
    "    S_sc[i] = S_sc[i-1] - q_as[i]*(t[i]*3600)\n",
    "    \n",
    "    S_bf[i] = S_bf[i-1] + q_ab[i]*(t[i]*3600) - q_f2[i]*(t[i]*3600)\n",
    "    S_sf[i] = S_sf[i-1] + q_as[i]*(t[i]*3600) - q_f1[i]*(t[i]*3600) + q_f2[i]*(t[i]*3600)\n",
    "        \n",
    "    S_s[i] = S_sc[i] + S_sf[i]\n",
    "    S_b[i] = S_bc[i] + S_bf[i]\n",
    "    \n",
    "    h_f[i] = (1/p)*(q_f1[i]*(t[i]*3600) + S_f[i-1])\n",
    "    \n",
    "    if d95 > h_f[i]:\n",
    "        k_s[i] = d95 - h_f[i]\n",
    "        n[i] = 0.0475*(k_s[i])**(1/6) #FIX THIS -- f_s should NOT exceed 1!!!!!!!\n",
    "    else:\n",
    "        n[i] = n_s\n",
    "    \n",
    "    f_s[i] = (n_s/n[i])**(1.5)\n",
    "    \n",
    "    #Calculate water depth assuming uniform overland flow\n",
    "    H[i] = ((n[i]*(rainfall[i]/3.6e6)*L)/(S**(1/2)))**(3/5)\n",
    "    \n",
    "    tau[i] = rho_w*g*H[i]*S\n",
    "    \n",
    "    #Calculate shear stress\n",
    "    shear_stress[i] = tau[i]*f_s[i]\n",
    "    \n",
    "    #Calculate sediment transport rate\n",
    "    if (shear_stress[i]-tau_c) >= 0:\n",
    "        q_s[i] = ((10**(-4.348))/(rho_s*((d50)**(0.811))))*(shear_stress[i]-tau_c)**(2.457)/L\n",
    "    else:\n",
    "        q_s[i] = 0\n",
    "\n",
    "    #Create a condition column based on sediment transport capacity vs sediment supply\n",
    "    sed_avail[i] = q_f1[i]*(t[i]*3600.)\n",
    "    sed_cap[i] = q_s[i]*(t_storm[i]*3600.)\n",
    "    value[i] = (sed_avail[i]-sed_cap[i])\n",
    "        \n",
    "    if value[i] < 0:\n",
    "        Hs_out[i] = np.minimum(sed_avail[i]+S_f[i-1], sed_cap[i])\n",
    "        dS_f[i] = sed_avail[i] - Hs_out[i]\n",
    "\n",
    "    else:\n",
    "        Hs_out[i] = sed_cap[i]\n",
    "        dS_f[i] = sed_avail[i] - Hs_out[i]\n",
    "\n",
    "    S_f[i] = S_f[i-1] + dS_f[i] if (S_f[i-1] + dS_f[i]) > 0 else 0\n",
    "    \n",
    "#Add all numpy arrays to the Pandas dataframe\n",
    "df['q_s'] = q_s\n",
    "df_storage['n'] = n\n",
    "df_storage['ks'] = k_s\n",
    "df_storage['water_depth'] = H\n",
    "df_storage['shear_stress'] = shear_stress\n",
    "df_storage['hf'] = h_f\n",
    "df_storage['f_s'] = f_s\n",
    "df_storage['q_s'] = q_s\n",
    "df_storage['qf1'] = q_f1\n",
    "df_storage['qf2'] = q_f2\n",
    "df_storage['dS_f'] = dS_f\n",
    "df_storage['S_f'] = S_f\n",
    "df_storage['S_s'] = S_s\n",
    "df_storage['S_sc'] = S_sc\n",
    "df_storage['S_sf'] = S_sf\n",
    "df_storage['S_b'] = S_b\n",
    "df_storage['S_bc'] = S_bc\n",
    "df_storage['S_bf'] = S_bf\n",
    "df_storage['Hs_out'] = Hs_out\n",
    "df_storage['sed_avail'] = sed_avail\n",
    "df_storage['sed_cap'] = sed_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_= df_storage.f_s.plot()\n",
    "f_s.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at our dataframe\n",
    "df_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resample to daily data again\n",
    "df_day_sed = df.resample('D').sum().fillna(0)\n",
    "df_day_sed['day'] = np.arange(0, len(df_day_sed), 1)\n",
    "\n",
    "#Plot sediment transport rates over time\n",
    "fig2, ax2 = plt.subplots(figsize=(7,5))\n",
    "df_day_sed.plot(y='q_s', ax=ax2, color = 'peru', legend=False)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(r'Sediment transport rate $(m/s)$')\n",
    "plt.title('Sediment transport rates', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\Sediment.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_storage.resample('D').mean().fillna(method='ffill')\n",
    "df4['day'] = np.arange(0, len(df4), 1)\n",
    "df4['S_f_mm'] = df4.S_f*1000\n",
    "df4['sed_cap_mm'] = df4.sed_cap/1e-3\n",
    "df4['Hs_out_mm'] = df4.Hs_out/1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig13, ax13 = plt.subplots(figsize=(7,4))\n",
    "df4.sed_cap_mm.plot(color = '#9e80c2', label='Transport capacity')\n",
    "df4.Hs_out_mm.plot(color='#442766', label='Actual transport')\n",
    "plt.xlabel('Date', fontsize=14, fontweight='bold')\n",
    "plt.ylabel(r'Sediment depth $(mm)$', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0,8)\n",
    "\n",
    "fig13.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax13.transAxes)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\CapacityVTransport.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots(figsize=(9,4.5))\n",
    "df4.plot(y='S_f_mm', ax=ax3, color = 'mediumseagreen', legend=False)\n",
    "plt.xlabel('Date', fontsize=14, fontweight='bold')\n",
    "plt.ylabel(r'Fine sediment storage, $S_f$ $(mm)$',fontsize=14, fontweight='bold')\n",
    "#plt.title('Fine sediment storage', fontweight='bold', fontsize=14)\n",
    "plt.ylim(0,1.4)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\FineStorage.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['sed_cap_mm'] = df4.sed_cap/1e-3\n",
    "\n",
    "fig8, ax8 = plt.subplots(figsize=(7,3))\n",
    "df4.plot(y='S_f_mm', ax=ax8, color = 'mediumseagreen', legend=False, label='Fine storage')\n",
    "df4.plot(y='Hs_out_mm', ax=ax8, color = '#442766', legend=False, label='Actual transport', alpha=0.75)\n",
    "\n",
    "ax8.set_xlabel('Date', fontsize=14, fontweight='bold')\n",
    "ax8.set_ylabel(r'Sediment depth $(mm)$', fontsize=14, fontweight='bold')\n",
    "ax8.set_ylim(0, 1.4)\n",
    "\n",
    "fig8.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax8.transAxes)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\CapacityVStorage.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig10, ax10 = plt.subplots(figsize=(10,7))\n",
    "df4.plot(y='qf1', ax=ax10, color = 'mediumturquoise', legend=False, label=r'$q_{f1}$')\n",
    "df4.plot(y='qf2', ax=ax10, color = 'mediumvioletred', legend=False, label=r'$q_{f2}$')\n",
    "\n",
    "ax10.set_ylabel(r'Sediment flux $(mm/s)$')\n",
    "ax10.set_xlabel('Date')\n",
    "fig10.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax10.transAxes)\n",
    "\n",
    "plt.title('Sediment layer fluxes', fontweight='bold', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['diff'] = df4.qf1-df4.qf2\n",
    "fig11, ax11 = plt.subplots(figsize=(10,7))\n",
    "df4.plot(y='diff', ax=ax11, color = 'mediumturquoise', legend=False)\n",
    "ax11.set_ylabel(r'Flux difference, $(mm/s)$')\n",
    "ax11.set_xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df_storage.resample('D').mean().fillna(method='ffill')\n",
    "#df5['hour'] = np.arange(0, len(df5), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, ax5 = plt.subplots(figsize=(7,4.5))\n",
    "\n",
    "df5.plot(y='S_s', ax=ax5, color = '#532287', legend=False, label='Total surfacing')\n",
    "df5.plot(y='S_sc', ax=ax5, color = '#b0077d', legend=False, label='Coarse surfacing')\n",
    "df5.plot(y='S_sf', ax=ax5, color = '#027fcc', legend=False, label='Fine surfacing')\n",
    "\n",
    "ax5.set_ylabel(r'Surfacing storage, $S_f$ $(m)$', fontweight='bold', fontsize=14)\n",
    "ax5.set_ylim(0, 0.25)\n",
    "#ax5.set_title('Surfacing storage', fontweight='bold', fontsize=14)\n",
    "fig5.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax5.transAxes)\n",
    "plt.xlabel('Date', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\SurfStorage.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7, ax7 = plt.subplots(figsize=(7,4.5))\n",
    "df5.plot(y='S_b', ax=ax7, color = '#12586b', legend=False, label='Total ballast')\n",
    "df5.plot(y='S_bc', ax=ax7, color = '#099c49', legend=False, label='Coarse ballast')\n",
    "df5.plot(y='S_bf', ax=ax7, color = '#2949e6', legend=False, label='Fine ballast')\n",
    "#ax7.set_ylim(0, 0.7)\n",
    "plt.xlabel('Date', fontweight='bold', fontsize=14)\n",
    "plt.ylabel(r'Ballast storage, $S_b$ $(m)$', fontweight='bold', fontsize=14)\n",
    "fig7.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax7.transAxes)\n",
    "#plt.title('Ballast storage', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\BalStorage.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig10, ax10 = plt.subplots(3, figsize=(9,4), sharex=True)\n",
    "df4.plot(y='S_f_mm', ax=ax10[0], color = 'mediumseagreen', legend=False, label='TAF elevation')\n",
    "df5.plot(y='S_s', ax=ax10[1], color = '#532287', legend=False, label='Surfacing elevation')\n",
    "df5.plot(y='S_b', ax=ax10[2], color = '#12586b', legend=False, label='Ballast elevation')\n",
    "\n",
    "plt.xlabel('Date', fontweight='bold', fontsize=14)\n",
    "ax10[0].set_ylabel(r'$S_f$ $(mm)$', fontweight='bold', fontsize=14)\n",
    "ax10[1].set_ylabel(r'$S_s$ $(m)$', fontweight='bold', fontsize=14)\n",
    "ax10[2].set_ylabel(r'$S_b$ $(m)$', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\100yrs.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data by water year\n",
    "yr_1 = df_storage.Hs_out['2018-10-01':'2019-09-30'].sum()\n",
    "yr_2 = df_storage.Hs_out['2019-10-01':'2020-09-30'].sum()\n",
    "yr_3 = df_storage.Hs_out['2020-10-01':'2021-09-30'].sum()\n",
    "yr_4 = df_storage.Hs_out['2021-10-01':'2022-09-30'].sum()\n",
    "yr_5 = df_storage.Hs_out['2022-10-01':'2023-09-30'].sum()\n",
    "yr_6 = df_storage.Hs_out['2023-10-01':'2024-09-30'].sum()\n",
    "yr_7 = df_storage.Hs_out['2024-10-01':'2025-09-30'].sum()\n",
    "yr_8 = df_storage.Hs_out['2025-10-01':'2026-09-30'].sum()\n",
    "yr_9 = df_storage.Hs_out['2026-10-01':'2027-09-30'].sum()\n",
    "yr_10 = df_storage.Hs_out['2027-10-01':'2028-09-30'].sum()\n",
    "yr_11 = df_storage.Hs_out['2028-10-01':'2029-09-30'].sum()\n",
    "yr_12 = df_storage.Hs_out['2029-10-01':'2030-09-30'].sum()\n",
    "yr_13 = df_storage.Hs_out['2030-10-01':'2031-09-30'].sum()\n",
    "yr_14 = df_storage.Hs_out['2031-10-01':'2032-09-30'].sum()\n",
    "yr_15 = df_storage.Hs_out['2032-10-01':'2033-09-30'].sum()\n",
    "yr_16 = df_storage.Hs_out['2033-10-01':'2034-09-30'].sum()\n",
    "yr_17 = df_storage.Hs_out['2034-10-01':'2035-09-30'].sum()\n",
    "yr_18 = df_storage.Hs_out['2035-10-01':'2036-09-30'].sum()\n",
    "yr_19 = df_storage.Hs_out['2036-10-01':'2037-09-30'].sum()\n",
    "yr_20 = df_storage.Hs_out['2037-10-01':'2038-09-30'].sum()\n",
    "\n",
    "\n",
    "#Multiply Hs_out\n",
    "sed_area = np.multiply([yr_1, yr_2, yr_3, yr_4, yr_5, yr_6, yr_7, \\\n",
    "                        yr_8, yr_9, yr_10, yr_11, yr_12, yr_13, yr_14, \\\n",
    "                        yr_15, yr_16, yr_17, yr_18, yr_19, yr_20], L)\n",
    "sed_load = np.multiply(sed_area, rho_s)\n",
    "years = [2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, \\\n",
    "         2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = years\n",
    "fig8, ax8 = plt.subplots(figsize=(7,4))\n",
    "plt.bar(years, sed_load, color = '#1d4f54')\n",
    "plt.xlabel('Water year', fontweight='bold', fontsize=14)\n",
    "plt.ylabel(r'Mass per meter of road $(kg/m)$', fontweight='bold', fontsize=14)\n",
    "#plt.title('Yearly sediment load per meter of road', fontweight='bold', fontsize=14)\n",
    "plt.xticks(range(ticks[0],ticks[len(ticks)-1]+1), ticks, rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r'C:\\Users\\Amanda\\Desktop\\AnnualYield.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do a sanity check. (i.e., is mass conserved?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_sum_m2 = df_storage.Hs_out.sum()\n",
    "sed_sum_kg_m = sed_sum_m2*rho_s*L\n",
    "round(sed_sum_kg_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (df_storage.S_s[0]-df_storage.S_s[len(df_storage)-1])\n",
    "b = (df_storage.S_b[0]-df_storage.S_b[len(df_storage)-1])\n",
    "f = (df_storage.S_f[0]-df_storage.S_f[len(df_storage)-1])\n",
    "\n",
    "round((s+b+f)*rho_s*L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
